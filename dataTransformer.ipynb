{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Tags: ['B-ACT', 'B-APT', 'B-EMAIL', 'B-ENCR', 'B-FILE', 'B-IDTY', 'B-IP', 'B-LOC', 'B-MAL', 'B-OS', 'B-PROT', 'B-SECTEAM', 'B-SHA2', 'B-TIME', 'B-TOOL', 'B-URL', 'B-VULID', 'B-VULNAME', 'E-ACT', 'E-APT', 'E-EMAIL', 'E-ENCR', 'E-FILE', 'E-IDTY', 'E-IP', 'E-LOC', 'E-MAL', 'E-OS', 'E-PROT', 'E-S-SECTEAM', 'E-SECTEAM', 'E-SHA2', 'E-TIME', 'E-TOOL', 'E-URL', 'E-VULNAME', 'I-ACT', 'I-APT', 'I-FILE', 'I-IDTY', 'I-LOC', 'I-MAL', 'I-OS', 'I-PROT', 'I-SECTEAM', 'I-TIME', 'I-TOOL', 'I-URL', 'I-VULNAME', 'O', 'PROT', 'S-ACT', 'S-APT', 'S-DOM', 'S-EMAIL', 'S-ENCR', 'S-FILE', 'S-IDTY', 'S-IP', 'S-LOC', 'S-MAL', 'S-MD5', 'S-OS', 'S-PROT', 'S-S-SECTEAM', 'S-SECTEAM', 'S-SHA1', 'S-SHA2', 'S-TIME', 'S-TOOL', 'S-URL', 'S-VULID', 'S-VULNAME']\n",
      "Sample:\n",
      "   sentence_id   word     tag\n",
      "0            0   From       O\n",
      "1            0  April  B-TIME\n",
      "2            0  19-24  I-TIME\n",
      "3            0      ,  I-TIME\n",
      "4            0   2017  E-TIME\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_bio_file(file_path):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == '':\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) == 2:\n",
    "                token, tag = parts\n",
    "                sentence.append((token, tag))\n",
    "\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def convert_to_dataframe(sentences):\n",
    "    data = {\n",
    "        \"sentence_id\": [],\n",
    "        \"word\": [],\n",
    "        \"tag\": []\n",
    "    }\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for token, tag in sentence:\n",
    "            data[\"sentence_id\"].append(i)\n",
    "            data[\"word\"].append(token)\n",
    "            data[\"tag\"].append(tag)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# ðŸ“Œ Replace this with your actual file path\n",
    "file_path = \"APTNERtrain.txt\"\n",
    "\n",
    "# ðŸ”§ Load and convert the BIO data\n",
    "sentences = load_bio_file(file_path)\n",
    "df = convert_to_dataframe(sentences)\n",
    "\n",
    "# âœ… Save to CSV for future use\n",
    "df.to_csv(\"ner_data_train.csv\", index=False)\n",
    "\n",
    "# âœ… Show entity tag types\n",
    "print(\"Unique Tags:\", sorted(df['tag'].unique()))\n",
    "print(\"Sample:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Tags: ['B-ACT', 'B-APT', 'B-FILE', 'B-IDTY', 'B-LOC', 'B-MAL', 'B-OS', 'B-PROT', 'B-SECTEAM', 'B-TIME', 'B-TOOL', 'B-VULID', 'B-VULNAME', 'E-ACT', 'E-APT', 'E-FILE', 'E-IDTY', 'E-LOC', 'E-MAL', 'E-OS', 'E-PROT', 'E-SECTEAM', 'E-TIME', 'E-TOOL', 'E-VULID', 'E-VULNAME', 'I-ACT', 'I-APT', 'I-FILE', 'I-IDTY', 'I-LOC', 'I-MAL', 'I-OS', 'I-PROT', 'I-SECTEAM', 'I-TIME', 'I-TOOL', 'O', 'S-ACT', 'S-APT', 'S-DOM', 'S-EMAIL', 'S-ENCR', 'S-FILE', 'S-IDTY', 'S-IP', 'S-LOC', 'S-MAL', 'S-MD5', 'S-OS', 'S-PROT', 'S-SECTEAM', 'S-SHA2', 'S-TIME', 'S-TOOL', 'S-URL', 'S-VULID', 'S-VULNAME']\n",
      "Sample:\n",
      "   sentence_id         word tag\n",
      "0            0          One   O\n",
      "1            0  certificate   O\n",
      "2            0          was   O\n",
      "3            0    generated   O\n",
      "4            0      locally   O\n"
     ]
    }
   ],
   "source": [
    "file_path = \"APTNERtest.txt\"\n",
    "\n",
    "# ðŸ”§ Load and convert the BIO data\n",
    "sentences = load_bio_file(file_path)\n",
    "df = convert_to_dataframe(sentences)\n",
    "\n",
    "# âœ… Save to CSV for future use\n",
    "df.to_csv(\"ner_data_test.csv\", index=False)\n",
    "\n",
    "# âœ… Show entity tag types\n",
    "print(\"Unique Tags:\", sorted(df['tag'].unique()))\n",
    "print(\"Sample:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn_crfsuite import CRF, metrics as crf_metrics\n",
    "import nltk\n",
    "from nltk.tag import hmm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"ner_data_train.csv\")\n",
    "test_df = pd.read_csv(\"ner_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=[\"word\", \"tag\"], inplace=True)\n",
    "test_df.dropna(subset=[\"word\", \"tag\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = str(sent[i][0]) if sent[i][0] is not None else \"\"\n",
    "\n",
    "    features = {\n",
    "        'word': word,\n",
    "        'is_upper': word.isupper(),\n",
    "        'is_title': word.istitle(),\n",
    "        'is_digit': word.isdigit()\n",
    "    }\n",
    "\n",
    "    # Previous word\n",
    "    if i > 0:\n",
    "        prev_word = str(sent[i - 1][0]) if sent[i - 1][0] is not None else \"\"\n",
    "        features.update({\n",
    "            '-1:word': prev_word,\n",
    "            '-1:is_title': prev_word.istitle()\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    # Next word\n",
    "    if i < len(sent) - 1:\n",
    "        next_word = str(sent[i + 1][0]) if sent[i + 1][0] is not None else \"\"\n",
    "        features.update({\n",
    "            '+1:word': next_word,\n",
    "            '+1:is_title': next_word.istitle()\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def prepare_data(df):\n",
    "    grouped = df.groupby(\"sentence_id\").apply(lambda x: list(zip(x[\"word\"], x[\"tag\"])))\n",
    "    return list(grouped)\n",
    "\n",
    "def extract_features_labels(sentences):\n",
    "    X, y = [], []\n",
    "    for sent in sentences:\n",
    "        X.append([word2features(sent, i) for i in range(len(sent))])\n",
    "        y.append([tag for _, tag in sent])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = prepare_data(train_df)\n",
    "test_sents = prepare_data(test_df)\n",
    "X_train_feats, y_train = extract_features_labels(train_sents)\n",
    "X_test_feats, y_test = extract_features_labels(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ MEMM Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ACT       0.10      0.80      0.18        10\n",
      "       B-APT       0.15      0.67      0.24        12\n",
      "      B-FILE       0.00      0.00      0.00         6\n",
      "      B-IDTY       0.03      0.08      0.04        25\n",
      "       B-LOC       0.54      0.73      0.62        26\n",
      "       B-MAL       0.06      0.27      0.10        15\n",
      "        B-OS       0.00      0.00      0.00         4\n",
      "      B-PROT       0.00      0.00      0.00         2\n",
      "   B-SECTEAM       0.72      0.54      0.62        24\n",
      "      B-TIME       0.82      0.49      0.61       177\n",
      "      B-TOOL       0.50      0.09      0.15       135\n",
      "     B-VULID       0.00      0.00      0.00         3\n",
      "   B-VULNAME       0.00      0.00      0.00         1\n",
      "       E-ACT       0.05      0.25      0.08        12\n",
      "       E-APT       0.15      0.67      0.24        12\n",
      "      E-FILE       0.00      0.00      0.00         6\n",
      "      E-IDTY       0.04      0.12      0.05        25\n",
      "       E-LOC       0.58      0.73      0.64        26\n",
      "       E-MAL       0.03      0.13      0.05        15\n",
      "        E-OS       0.00      0.00      0.00         4\n",
      "      E-PROT       0.00      0.00      0.00         2\n",
      "   E-SECTEAM       0.82      0.58      0.68        24\n",
      "      E-TIME       0.86      0.68      0.76       176\n",
      "      E-TOOL       0.61      0.10      0.18       135\n",
      "     E-VULID       0.00      0.00      0.00         3\n",
      "   E-VULNAME       0.00      0.00      0.00         1\n",
      "       I-ACT       0.29      0.67      0.40         3\n",
      "       I-APT       0.00      0.00      0.00         3\n",
      "      I-FILE       0.00      0.00      0.00        29\n",
      "      I-IDTY       0.00      0.00      0.00        41\n",
      "       I-LOC       0.00      0.00      0.00         3\n",
      "       I-MAL       0.00      0.00      0.00         3\n",
      "        I-OS       0.00      0.00      0.00         1\n",
      "      I-PROT       0.00      0.00      0.00         2\n",
      "   I-SECTEAM       0.75      0.56      0.64        16\n",
      "      I-TIME       0.50      0.04      0.08       135\n",
      "      I-TOOL       0.44      0.09      0.15        44\n",
      "           O       0.95      0.98      0.96     34905\n",
      "       S-ACT       0.45      0.61      0.52        41\n",
      "       S-APT       0.85      0.69      0.76       466\n",
      "       S-DOM       0.00      0.00      0.00        43\n",
      "     S-EMAIL       0.00      0.00      0.00        23\n",
      "      S-ENCR       1.00      0.88      0.94        41\n",
      "      S-FILE       0.50      0.13      0.21        90\n",
      "      S-IDTY       0.36      0.30      0.33       101\n",
      "        S-IP       0.00      0.00      0.00        35\n",
      "       S-LOC       0.61      0.81      0.70       140\n",
      "       S-MAL       0.76      0.25      0.38       716\n",
      "       S-MD5       0.00      0.00      0.00        32\n",
      "        S-OS       0.86      0.77      0.81        31\n",
      "      S-PROT       0.77      0.32      0.45        85\n",
      "   S-SECTEAM       0.97      0.87      0.92       167\n",
      "      S-SHA2       0.09      0.11      0.10        27\n",
      "      S-TIME       0.66      0.65      0.66       100\n",
      "      S-TOOL       0.97      0.38      0.54       739\n",
      "       S-URL       0.00      0.00      0.00         8\n",
      "     S-VULID       0.44      0.63      0.52        30\n",
      "   S-VULNAME       0.14      0.62      0.23        13\n",
      "\n",
      "    accuracy                           0.92     38994\n",
      "   macro avg       0.32      0.30      0.27     38994\n",
      "weighted avg       0.92      0.92      0.91     38994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_flat = [f for seq in X_train_feats for f in seq]\n",
    "y_flat = [t for seq in y_train for t in seq]\n",
    "X_test_flat = [f for seq in X_test_feats for f in seq]\n",
    "y_test_flat = [t for seq in y_test for t in seq]\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X_train_vec = vec.fit_transform(X_flat)\n",
    "X_test_vec = vec.transform(X_test_flat)\n",
    "\n",
    "all_labels = y_flat + y_test_flat\n",
    "le = LabelEncoder()\n",
    "le.fit(all_labels)\n",
    "\n",
    "y_train_enc = le.transform(y_flat)\n",
    "y_test_enc = le.transform(y_test_flat)\n",
    "\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train_vec, y_train_enc)\n",
    "y_pred_enc = clf.predict(X_test_vec)\n",
    "y_pred = le.inverse_transform(y_pred_enc)\n",
    "\n",
    "print(\"ðŸ“Œ MEMM Results:\\n\")\n",
    "print(classification_report(y_test_flat, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ CRF Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ACT       0.12      0.80      0.21        10\n",
      "       B-APT       0.15      0.83      0.26        12\n",
      "      B-FILE       0.00      0.00      0.00         6\n",
      "      B-IDTY       0.03      0.12      0.05        25\n",
      "       B-LOC       0.55      0.69      0.61        26\n",
      "       B-MAL       0.04      0.20      0.07        15\n",
      "        B-OS       1.00      0.25      0.40         4\n",
      "      B-PROT       0.00      0.00      0.00         2\n",
      "   B-SECTEAM       0.74      0.58      0.65        24\n",
      "      B-TIME       0.80      0.58      0.68       177\n",
      "      B-TOOL       0.48      0.12      0.19       135\n",
      "     B-VULID       0.00      0.00      0.00         3\n",
      "   B-VULNAME       0.00      0.00      0.00         1\n",
      "       E-ACT       0.09      0.50      0.15        12\n",
      "       E-APT       0.12      0.67      0.21        12\n",
      "      E-FILE       0.00      0.00      0.00         6\n",
      "      E-IDTY       0.03      0.12      0.05        25\n",
      "       E-LOC       0.55      0.69      0.61        26\n",
      "       E-MAL       0.04      0.20      0.07        15\n",
      "        E-OS       1.00      0.25      0.40         4\n",
      "      E-PROT       0.00      0.00      0.00         2\n",
      "   E-SECTEAM       0.68      0.54      0.60        24\n",
      "      E-TIME       0.88      0.64      0.74       176\n",
      "      E-TOOL       0.45      0.11      0.18       135\n",
      "     E-VULID       0.00      0.00      0.00         3\n",
      "   E-VULNAME       0.00      0.00      0.00         1\n",
      "       I-ACT       0.11      0.33      0.17         3\n",
      "       I-APT       0.00      0.00      0.00         3\n",
      "      I-FILE       0.00      0.00      0.00        29\n",
      "      I-IDTY       0.00      0.00      0.00        41\n",
      "       I-LOC       0.00      0.00      0.00         3\n",
      "       I-MAL       0.00      0.00      0.00         3\n",
      "        I-OS       1.00      1.00      1.00         1\n",
      "      I-PROT       0.00      0.00      0.00         2\n",
      "   I-SECTEAM       0.55      0.69      0.61        16\n",
      "      I-TIME       0.70      0.14      0.23       135\n",
      "      I-TOOL       0.44      0.18      0.26        44\n",
      "           O       0.94      0.98      0.96     34905\n",
      "       S-ACT       0.76      0.63      0.69        41\n",
      "       S-APT       0.85      0.48      0.61       466\n",
      "       S-DOM       0.00      0.00      0.00        43\n",
      "     S-EMAIL       0.00      0.00      0.00        23\n",
      "      S-ENCR       1.00      0.29      0.45        41\n",
      "      S-FILE       0.27      0.04      0.08        90\n",
      "      S-IDTY       0.38      0.26      0.31       101\n",
      "        S-IP       0.00      0.00      0.00        35\n",
      "       S-LOC       0.53      0.76      0.63       140\n",
      "       S-MAL       0.68      0.13      0.22       716\n",
      "       S-MD5       0.00      0.00      0.00        32\n",
      "        S-OS       0.89      0.81      0.85        31\n",
      "      S-PROT       0.88      0.27      0.41        85\n",
      "   S-SECTEAM       0.99      0.80      0.88       167\n",
      "      S-SHA2       0.18      0.26      0.22        27\n",
      "      S-TIME       0.64      0.55      0.59       100\n",
      "      S-TOOL       0.92      0.36      0.52       739\n",
      "       S-URL       0.00      0.00      0.00         8\n",
      "     S-VULID       0.70      0.47      0.56        30\n",
      "   S-VULNAME       0.09      0.38      0.14        13\n",
      "\n",
      "    accuracy                           0.91     38994\n",
      "   macro avg       0.37      0.31      0.29     38994\n",
      "weighted avg       0.91      0.91      0.90     38994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = CRF(algorithm='lbfgs', max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(X_train_feats, y_train)\n",
    "y_pred_crf = crf.predict(X_test_feats)\n",
    "\n",
    "print(\"ðŸ“Œ CRF Results:\\n\")\n",
    "print(crf_metrics.flat_classification_report(y_test, y_pred_crf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ HMM Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ACT       0.05      0.50      0.10        10\n",
      "       B-APT       0.10      0.75      0.18        12\n",
      "     B-EMAIL       0.00      0.00      0.00         0\n",
      "      B-FILE       0.00      0.00      0.00         6\n",
      "      B-IDTY       0.04      0.16      0.06        25\n",
      "       B-LOC       0.39      0.58      0.47        26\n",
      "       B-MAL       0.00      0.00      0.00        15\n",
      "        B-OS       1.00      0.50      0.67         4\n",
      "      B-PROT       0.00      0.00      0.00         2\n",
      "   B-SECTEAM       0.63      0.50      0.56        24\n",
      "      B-TIME       0.78      0.38      0.52       177\n",
      "      B-TOOL       0.20      0.07      0.11       135\n",
      "     B-VULID       0.00      0.00      0.00         3\n",
      "   B-VULNAME       0.00      0.00      0.00         1\n",
      "       E-ACT       0.03      0.25      0.06        12\n",
      "       E-APT       0.10      0.75      0.18        12\n",
      "     E-EMAIL       0.00      0.00      0.00         0\n",
      "      E-FILE       0.00      0.00      0.00         6\n",
      "      E-IDTY       0.03      0.12      0.04        25\n",
      "       E-LOC       0.39      0.58      0.47        26\n",
      "       E-MAL       0.00      0.00      0.00        15\n",
      "        E-OS       1.00      0.50      0.67         4\n",
      "      E-PROT       0.00      0.00      0.00         2\n",
      "   E-SECTEAM       0.68      0.54      0.60        24\n",
      "      E-TIME       0.85      0.42      0.56       176\n",
      "      E-TOOL       0.19      0.07      0.10       135\n",
      "     E-VULID       0.00      0.00      0.00         3\n",
      "   E-VULNAME       0.00      0.00      0.00         1\n",
      "       I-ACT       0.06      0.67      0.11         3\n",
      "       I-APT       0.33      0.67      0.44         3\n",
      "      I-FILE       0.00      0.00      0.00        29\n",
      "      I-IDTY       0.03      0.02      0.03        41\n",
      "       I-LOC       0.00      0.00      0.00         3\n",
      "       I-MAL       0.00      0.00      0.00         3\n",
      "        I-OS       1.00      1.00      1.00         1\n",
      "      I-PROT       0.00      0.00      0.00         2\n",
      "   I-SECTEAM       0.80      0.50      0.62        16\n",
      "      I-TIME       0.59      0.20      0.30       135\n",
      "      I-TOOL       0.38      0.14      0.20        44\n",
      "           O       0.94      0.97      0.95     34905\n",
      "       S-ACT       0.73      0.54      0.62        41\n",
      "       S-APT       0.85      0.60      0.70       466\n",
      "       S-DOM       0.00      0.00      0.00        43\n",
      "     S-EMAIL       0.00      0.00      0.00        23\n",
      "      S-ENCR       1.00      0.24      0.39        41\n",
      "      S-FILE       0.56      0.11      0.19        90\n",
      "      S-IDTY       0.19      0.11      0.14       101\n",
      "        S-IP       0.00      0.00      0.00        35\n",
      "       S-LOC       0.71      0.55      0.62       140\n",
      "       S-MAL       0.85      0.47      0.60       716\n",
      "       S-MD5       0.00      0.00      0.00        32\n",
      "        S-OS       0.88      0.45      0.60        31\n",
      "      S-PROT       0.53      0.20      0.29        85\n",
      "   S-SECTEAM       0.94      0.72      0.82       167\n",
      "      S-SHA2       0.00      0.00      0.00        27\n",
      "      S-TIME       0.74      0.51      0.60       100\n",
      "      S-TOOL       0.88      0.22      0.35       739\n",
      "       S-URL       0.00      0.00      0.00         8\n",
      "     S-VULID       1.00      0.53      0.70        30\n",
      "   S-VULNAME       0.12      0.38      0.19        13\n",
      "\n",
      "    accuracy                           0.90     38994\n",
      "   macro avg       0.34      0.27      0.26     38994\n",
      "weighted avg       0.91      0.90      0.90     38994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_hmm = [[(w, t) for w, t in sent] for sent in train_sents]\n",
    "test_data_hmm = [[w for w, t in sent] for sent in test_sents]\n",
    "test_tags_hmm = [[t for w, t in sent] for sent in test_sents]\n",
    "\n",
    "hmm_trainer = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_model = hmm_trainer.train_supervised(train_data_hmm)\n",
    "\n",
    "hmm_pred = [hmm_model.tag(sent) for sent in test_data_hmm]\n",
    "y_pred_hmm = [[tag for _, tag in sent] for sent in hmm_pred]\n",
    "\n",
    "y_true = [t for seq in test_tags_hmm for t in seq]\n",
    "y_pred = [t for seq in y_pred_hmm for t in seq]\n",
    "\n",
    "print(\"ðŸ“Œ HMM Results:\\n\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memm_label_encoder.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the MEMM model, vectorizer, and label encoder\n",
    "joblib.dump(clf, \"memm_model.joblib\")\n",
    "joblib.dump(vec, \"memm_vectorizer.joblib\")\n",
    "joblib.dump(le, \"memm_label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"crf_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(crf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "with open(\"hmm_model.dill\", \"wb\") as f:\n",
    "    dill.dump(hmm_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m os_tokens \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word, tag \u001b[38;5;129;01min\u001b[39;00m X_flat \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOS\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tag]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mset\u001b[39m(os_tokens))\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "os_tokens = [word for word, tag in X_flat if \"OS\" in tag]\n",
    "print(set(os_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS-related tokens in training data: {'Win64', 'X', 'Linux-based', 'Creators', 'Xp/2003', 'Unix-based', 'Update', 'OSX', 'OS', 'operating', 'XP', 'Windows-based', 'macOS', '%ALLUSERSPROFILE%\\\\Windows', 'MS', 'Unix', 'Apple', 'MAC', 'Microsoft\\\\Windows', 'Mac', 'windows', 'The', 'HKLM\\\\SOFTWARE\\\\Microsoft\\\\Windows', 'SysWoW64', 'systems', 'Android', 'â€™s', 'Win32', 'the', 'UNIX', 'MacOS', 'Unix-', 'Win', 'Linux', '10', 'Windows', 'Linux-'}\n"
     ]
    }
   ],
   "source": [
    "# If using HMM format like [[(word, tag), ...], ...]\n",
    "os_tokens = [word for sent in train_data_hmm for word, tag in sent if \"OS\" in tag]\n",
    "print(\"OS-related tokens in training data:\", set(os_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
